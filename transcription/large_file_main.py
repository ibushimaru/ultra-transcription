"""
Large file transcription application with chunked processing.
Designed for 2+ hour audio files with memory efficiency.
"""

import click
import os
import time
from pathlib import Path
from typing import Optional

from .chunked_transcriber import ChunkedTranscriber
from .post_processor import TranscriptionPostProcessor
from .output_formatter import OutputFormatter
from .time_estimator import TranscriptionTimeEstimator


class LargeFileProgressCallback:
    """Progress callback for large file processing."""
    
    def __init__(self, estimated_time: float):
        self.estimated_time = estimated_time
        self.start_time = time.time()
        self.last_update = 0
        
    def __call__(self, stage: str, progress: float, extra_info=None):
        """Handle progress updates."""
        current_time = time.time()
        
        # Update every 5 seconds to avoid spam
        if current_time - self.last_update < 5.0 and progress < 1.0:
            return
            
        elapsed = current_time - self.start_time
        
        if progress > 0:
            estimated_total = elapsed / progress
            remaining = max(0, estimated_total - elapsed)
        else:
            remaining = self.estimated_time
        
        # Create progress bar
        bar_length = 25
        filled_length = int(bar_length * progress)
        bar = 'â–ˆ' * filled_length + 'â–‘' * (bar_length - filled_length)
        
        # Format stage info
        stage_info = {
            'chunking': 'ğŸ“¦ ãƒãƒ£ãƒ³ã‚¯åˆ†å‰²',
            'extracting': 'âœ‚ï¸ ãƒãƒ£ãƒ³ã‚¯æŠ½å‡º',
            'processing': 'ğŸ”„ ãƒãƒ£ãƒ³ã‚¯å‡¦ç†',
            'transcription': 'ğŸ“ æ–‡å­—èµ·ã“ã—',
            'merging': 'ğŸ”— çµæœçµ±åˆ',
            'post_processing': 'ğŸ”§ å¾Œå‡¦ç†',
            'saving': 'ğŸ’¾ ä¿å­˜'
        }
        
        stage_name = stage_info.get(stage, stage)
        
        # Extra info display
        extra_str = ""
        if extra_info:
            if isinstance(extra_info, int):
                extra_str = f" ({extra_info})"
            elif isinstance(extra_info, str):
                extra_str = f" ({extra_info})"
        
        print(f"\r{stage_name} [{bar}] {progress:.1%}{extra_str} | "
              f"çµŒé: {self._format_time(elapsed)} | æ®‹ã‚Š: {self._format_time(remaining)}", 
              end='', flush=True)
        
        if progress >= 1.0:
            print()  # New line when stage completes
            
        self.last_update = current_time
    
    def _format_time(self, seconds: float) -> str:
        """Format time in human-readable format."""
        if seconds < 60:
            return f"{seconds:.0f}s"
        elif seconds < 3600:
            return f"{seconds/60:.1f}m"
        else:
            return f"{seconds/3600:.1f}h"


@click.command()
@click.argument('audio_file', type=click.Path(exists=True))
@click.option('--output', '-o', help='Output file base path (without extension)')
@click.option('--model', '-m', default='large-v3-turbo', 
              type=click.Choice(['tiny', 'base', 'small', 'medium', 'large', 'large-v3', 'large-v3-turbo', 'turbo']),
              help='Whisper model size (default: large-v3-turbo for maximum speed)')
@click.option('--language', '-l', default='ja', help='Language code for transcription')
@click.option('--min-confidence', default=0.3, type=float,
              help='Minimum confidence threshold for segments')
@click.option('--chunk-duration', default=10, type=int,
              help='Chunk duration in minutes (default: 10)')
@click.option('--overlap-duration', default=2.0, type=float,
              help='Overlap between chunks in seconds (default: 2.0)')
@click.option('--max-memory', default=512, type=int,
              help='Maximum memory per chunk in MB (default: 512)')
@click.option('--no-enhanced-preprocessing', is_flag=True,
              help='Skip enhanced audio preprocessing')
@click.option('--no-post-processing', is_flag=True,
              help='Skip post-processing corrections')
@click.option('--no-filter-fillers', is_flag=True,
              help='Skip filler word filtering')
@click.option('--format', 'output_format', 
              type=click.Choice(['all', 'json', 'csv', 'txt', 'srt']),
              default='all', help='Output format')
@click.option('--device', default='cpu', type=click.Choice(['cpu', 'cuda']),
              help='Device to run on (cpu, cuda)')
@click.option('--auto-confirm', is_flag=True,
              help='Skip confirmation for long processes')
def large_file_transcribe(audio_file: str, output: Optional[str], model: str, language: str,
                         min_confidence: float, chunk_duration: int, overlap_duration: float,
                         max_memory: int, no_enhanced_preprocessing: bool,
                         no_post_processing: bool, no_filter_fillers: bool, 
                         output_format: str, device: str, auto_confirm: bool):
    """
    Large file transcription with chunked processing.
    
    Designed for 2+ hour audio files with memory efficiency.
    Automatically handles memory management and progress tracking.
    
    AUDIO_FILE: Path to the audio file (MP3, WAV, etc.)
    """
    
    print("ğŸ—ï¸  LARGE FILE éŸ³å£°æ–‡å­—èµ·ã“ã—ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³")
    print("=" * 70)
    print("ğŸ“‹ å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆ2æ™‚é–“ä»¥ä¸Šï¼‰å¯¾å¿œãƒ»ãƒ¡ãƒ¢ãƒªåŠ¹ç‡æœ€é©åŒ–")
    print("=" * 70)
    
    # Validate input file
    if not os.path.exists(audio_file):
        click.echo(f"Error: Audio file not found: {audio_file}", err=True)
        return
    
    # Check file size
    file_size_mb = os.path.getsize(audio_file) / (1024 * 1024)
    print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size_mb:.1f}MB")
    
    # Set default output path if not provided
    if not output:
        audio_path = Path(audio_file)
        output = str(audio_path.parent / f"{audio_path.stem}_large_file")
    
    try:
        # Estimate processing time for large files
        estimator = TranscriptionTimeEstimator()
        
        print("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æä¸­...")
        
        # Get rough duration estimate (without loading full file)
        from pydub import AudioSegment
        try:
            audio_segment = AudioSegment.from_file(audio_file)
            audio_duration = len(audio_segment) / 1000.0
            del audio_segment  # Free memory immediately
        except Exception as e:
            print(f"âš ï¸  Duration analysis failed: {e}")
            # Rough estimate based on file size (MP3: ~1MB per minute)
            audio_duration = file_size_mb * 60  # Conservative estimate
        
        print(f"ğŸµ æ¨å®šéŸ³å£°é•·: {audio_duration/60:.1f}åˆ† ({audio_duration/3600:.1f}æ™‚é–“)")
        
        # Adjust chunk size for very large files
        if audio_duration > 7200:  # 2+ hours
            recommended_chunk = max(15, chunk_duration)  # At least 15 minutes
            if chunk_duration < recommended_chunk:
                print(f"ğŸ“Š å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«æ¤œå‡º: ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºã‚’{chunk_duration}åˆ†â†’{recommended_chunk}åˆ†ã«èª¿æ•´")
                chunk_duration = recommended_chunk
        
        # Generate time estimate using chunked processing parameters
        estimates = estimator.estimate_processing_time(
            audio_duration=audio_duration,
            model_size=model,
            device=device,
            engine='chunked-enhanced',
            enhanced_preprocessing=not no_enhanced_preprocessing,
            post_processing=not no_post_processing,
            speaker_diarization=False  # Not implemented in chunked version yet
        )
        
        # Apply chunked processing efficiency (usually 20-30% faster)
        chunking_efficiency = 0.75  # 25% improvement from chunking
        for key in ['optimistic', 'realistic', 'pessimistic']:
            estimates[key] *= chunking_efficiency
        
        # Display time estimation
        print("\\n" + "â±ï¸" * 3 + " å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†æ™‚é–“äºˆæ¸¬ " + "â±ï¸" * 3)
        print("=" * 65)
        print(f"ğŸµ éŸ³å£°é•·: {estimator.format_time_estimate(audio_duration)}")
        print(f"ğŸ“¦ ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚º: {chunk_duration}åˆ† (ã‚ªãƒ¼ãƒãƒ¼ãƒ©ãƒƒãƒ—: {overlap_duration}ç§’)")
        print(f"ğŸ§  ãƒ¡ãƒ¢ãƒªåˆ¶é™: {max_memory}MB/ãƒãƒ£ãƒ³ã‚¯")
        print(f"âš¡ æœ€çŸ­äºˆæƒ³: {estimator.format_time_estimate(estimates['optimistic'])}")
        print(f"ğŸ¯ æ¨™æº–äºˆæƒ³: {estimator.format_time_estimate(estimates['realistic'])}")
        print(f"â³ æœ€é•·äºˆæƒ³: {estimator.format_time_estimate(estimates['pessimistic'])}")
        print(f"ğŸ“Š å‡¦ç†æ¯”ç‡: {estimates['processing_ratio']:.2f}x")
        print("=" * 65)
        
        # Warning for very long processing times
        if estimates['realistic'] > 1800:  # 30 minutes
            print(f"âš ï¸  é•·æ™‚é–“å‡¦ç†äºˆæƒ³: {estimator.format_time_estimate(estimates['realistic'])}")
            print("ğŸ’¡ ãƒ’ãƒ³ãƒˆ: ã‚ˆã‚Šå°ã•ãªãƒ¢ãƒ‡ãƒ«ï¼ˆtiny/baseï¼‰ã‚„CUDAã®ä½¿ç”¨ã‚’æ¤œè¨ã—ã¦ãã ã•ã„")
        
        # Ask for confirmation on long processes
        if estimates['realistic'] > 600 and not auto_confirm:  # 10 minutes
            print(f"âš ï¸  å‡¦ç†ã«{estimator.format_time_estimate(estimates['realistic'])}ã‹ã‹ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")
            if not click.confirm("ç¶šè¡Œã—ã¾ã™ã‹ï¼Ÿ"):
                return
        
        # Initialize chunked transcriber
        print("\\nğŸ”§ ãƒãƒ£ãƒ³ã‚¯å‡¦ç†ã‚·ã‚¹ãƒ†ãƒ åˆæœŸåŒ–ä¸­...")
        transcriber = ChunkedTranscriber(
            model_size=model,
            language=language,
            device=device,
            chunk_duration=chunk_duration,
            overlap_duration=overlap_duration,
            max_memory_mb=max_memory
        )
        
        # Initialize progress tracking
        progress_callback = LargeFileProgressCallback(estimates['realistic'])
        
        start_time = time.time()
        
        try:
            # Process large file with chunked approach
            print("\\nğŸš€ ãƒãƒ£ãƒ³ã‚¯å‡¦ç†é–‹å§‹...")
            segments = transcriber.process_large_file(
                audio_file=audio_file,
                enhanced_preprocessing=not no_enhanced_preprocessing,
                filter_fillers=not no_filter_fillers,
                min_confidence=min_confidence,
                progress_callback=progress_callback
            )
            
            if not segments:
                print("âš ï¸  æ–‡å­—èµ·ã“ã—çµæœãŒå¾—ã‚‰ã‚Œã¾ã›ã‚“ã§ã—ãŸ")
                return
            
            print(f"\\nâœ… ãƒãƒ£ãƒ³ã‚¯å‡¦ç†å®Œäº†: {len(segments)} ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")
            
            # Post-processing
            if not no_post_processing:
                progress_callback("post_processing", 0.0)
                print("ğŸ”§ å¾Œå‡¦ç†é©ç”¨ä¸­...")
                
                post_processor = TranscriptionPostProcessor()
                segments = post_processor.process_transcription(segments)
                
                progress_callback("post_processing", 1.0)
                print(f"âœ… å¾Œå‡¦ç†å®Œäº†: {len(segments)} ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ")
            
            # Save output
            progress_callback("saving", 0.0)
            print(f"ğŸ’¾ çµæœä¿å­˜ä¸­: {output}")
            
            output_formatter = OutputFormatter()
            
            # Prepare metadata
            processing_time = time.time() - start_time
            avg_confidence = sum(seg["confidence"] for seg in segments) / len(segments)
            
            metadata = {
                "input_file": audio_file,
                "model_size": model,
                "language": language,
                "device": device,
                "engine": "chunked-enhanced",
                "processing_time_seconds": round(processing_time, 2),
                "audio_duration_seconds": audio_duration,
                "processing_ratio": round(processing_time / audio_duration, 3),
                "average_confidence": round(avg_confidence, 3),
                "estimated_time": round(estimates['realistic'], 2),
                "estimation_accuracy": round(abs(processing_time - estimates['realistic']) / estimates['realistic'], 3),
                "total_segments": len(segments),
                "chunk_duration_minutes": chunk_duration,
                "max_memory_mb": max_memory,
                "file_size_mb": round(file_size_mb, 1)
            }
            
            if output_format == 'all':
                saved_files = output_formatter.save_all_formats(segments, output, metadata)
                progress_callback("saving", 1.0, "å…¨å½¢å¼")
            else:
                output_data = output_formatter.prepare_output_data(segments)
                
                if output_format == 'json':
                    output_formatter.save_as_json(output_data, f"{output}.json", metadata)
                elif output_format == 'csv':
                    output_formatter.save_as_csv(output_data, f"{output}.csv")
                elif output_format == 'txt':
                    output_formatter.save_as_txt(output_data, f"{output}.txt")
                elif output_format == 'srt':
                    output_formatter.save_as_srt(output_data, f"{output}.srt")
                
                progress_callback("saving", 1.0, output_format.upper())
            
        finally:
            # Clean up transcriber resources
            transcriber.cleanup()
        
        # Final results
        processing_time = time.time() - start_time
        
        print("\\n" + "=" * 70)
        print("ğŸ¯ LARGE FILE PROCESSING RESULTS")
        print("=" * 70)
        print(f"â±ï¸  å®Ÿéš›ã®å‡¦ç†æ™‚é–“: {estimator.format_time_estimate(processing_time)}")
        print(f"ğŸ”® äºˆæƒ³å‡¦ç†æ™‚é–“: {estimator.format_time_estimate(estimates['realistic'])}")
        
        # Calculate prediction accuracy
        accuracy = abs(processing_time - estimates['realistic']) / estimates['realistic']
        if accuracy < 0.2:
            accuracy_emoji = "ğŸ¯"
            accuracy_text = "å„ªç§€"
        elif accuracy < 0.4:
            accuracy_emoji = "ğŸ“Š"
            accuracy_text = "è‰¯å¥½"
        else:
            accuracy_emoji = "ğŸ“ˆ"
            accuracy_text = "è¦æ”¹å–„"
        
        print(f"{accuracy_emoji} äºˆæ¸¬ç²¾åº¦: {accuracy_text} (èª¤å·®: {accuracy:.1%})")
        print(f"ğŸ“Š å¹³å‡ä¿¡é ¼åº¦: {avg_confidence:.1%}")
        print(f"ğŸ“ ç·ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ: {len(segments)}")
        print(f"âš¡ å‡¦ç†é€Ÿåº¦: {processing_time/audio_duration:.2f}x")
        print(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size_mb:.1f}MB")
        print(f"ğŸ§  ãƒ¡ãƒ¢ãƒªåŠ¹ç‡: {max_memory}MB/ãƒãƒ£ãƒ³ã‚¯")
        print("=" * 70)
        print("ğŸ‰ å¤§å®¹é‡ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†å®Œäº†!")
        
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ: {e}")
        raise


def cli():
    """Large file audio transcription CLI application."""
    large_file_transcribe()


if __name__ == '__main__':
    cli()